{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "import pickle\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the dataset\n",
    "df = pd.read_csv(\"student-scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop unnecessary columns\n",
    "df.drop(columns=['id', 'first_name', 'last_name', 'email'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate total and average scores\n",
    "df[\"total_score\"] = (\n",
    "    df[\"math_score\"] + df[\"history_score\"] + df[\"physics_score\"] +\n",
    "    df[\"chemistry_score\"] + df[\"biology_score\"] + df[\"english_score\"] + df[\"geography_score\"]\n",
    ")\n",
    "df[\"average_score\"] = df[\"total_score\"] / 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map categorical variables\n",
    "gender_map = {'male': 0, 'female': 1}\n",
    "part_time_job_map = {False: 0, True: 1}\n",
    "extracurricular_activities_map = {False: 0, True: 1}\n",
    "career_aspiration_map = {\n",
    "    'Lawyer': 0, 'Doctor': 1, 'Government Officer': 2, 'Artist': 3, 'Unknown': 4,\n",
    "    'Software Engineer': 5, 'Teacher': 6, 'Business Owner': 7, 'Scientist': 8,\n",
    "    'Banker': 9, 'Writer': 10, 'Accountant': 11, 'Designer': 12,\n",
    "    'Construction Engineer': 13, 'Game Developer': 14, 'Stock Investor': 15,\n",
    "    'Real Estate Developer': 16\n",
    "}\n",
    "\n",
    "df['gender'] = df['gender'].map(gender_map)\n",
    "df['part_time_job'] = df['part_time_job'].map(part_time_job_map)\n",
    "df['extracurricular_activities'] = df['extracurricular_activities'].map(extracurricular_activities_map)\n",
    "df['career_aspiration'] = df['career_aspiration'].map(career_aspiration_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle imbalanced data using SMOTE\n",
    "X = df.drop('career_aspiration', axis=1)\n",
    "y = df['career_aspiration']\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Model: Logistic Regression\n",
      "Accuracy: 0.47432306255835666\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.51      0.48        68\n",
      "           1       0.49      0.67      0.57        72\n",
      "           2       0.38      0.42      0.40        57\n",
      "           3       0.53      0.53      0.53        58\n",
      "           4       0.35      0.17      0.23        66\n",
      "           5       0.33      0.32      0.32        76\n",
      "           6       0.54      0.89      0.67        71\n",
      "           7       0.79      0.79      0.79        61\n",
      "           8       0.45      0.47      0.46        53\n",
      "           9       0.22      0.07      0.10        61\n",
      "          10       0.58      0.75      0.65        63\n",
      "          11       0.44      0.47      0.45        53\n",
      "          12       0.28      0.13      0.18        68\n",
      "          13       0.35      0.47      0.40        55\n",
      "          14       0.60      0.89      0.72        57\n",
      "          15       0.34      0.22      0.27        63\n",
      "          16       0.50      0.33      0.40        69\n",
      "\n",
      "    accuracy                           0.47      1071\n",
      "   macro avg       0.45      0.48      0.45      1071\n",
      "weighted avg       0.45      0.47      0.45      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[35  4  0  0  0  7  0  0  4  1 11  4  0  2  0  0  0]\n",
      " [ 2 48  0  0  0  7  0  0 10  0  0  0  0  5  0  0  0]\n",
      " [ 0  0 24  3  2  1 10  1  0  0  2  0  3  2  2  3  4]\n",
      " [ 0  0  2 31  0  0  3  4  0  0  0  0  0  0  9  0  9]\n",
      " [ 5  5  9  3 11  9  7  0  4  2  0  3  3  2  1  1  1]\n",
      " [ 8 10  0  0  1 24  1  0  0  7  1  6  2 11  0  5  0]\n",
      " [ 0  0  0  0  1  2 63  0  0  1  3  0  1  0  0  0  0]\n",
      " [ 0  0  0  3  0  0  0 48  0  0  0  0  0  0  7  0  3]\n",
      " [ 3 18  0  0  0  1  0  0 25  0  6  0  0  0  0  0  0]\n",
      " [11  1  0  0  3  7 10  0  1  4  3  7  6  6  0  2  0]\n",
      " [ 7  3  0  0  0  0  3  0  1  1 47  1  0  0  0  0  0]\n",
      " [ 0  1  0  0  4  6  3  0  3  1  0 25  0  4  0  6  0]\n",
      " [ 2  2 11  3  4  2  8  0  3  0  4  0  9  7  6  5  2]\n",
      " [ 2  2  3  0  2  0  0  0  5  1  1  5  4 26  0  4  0]\n",
      " [ 0  0  0  3  0  0  0  2  0  0  0  0  0  0 51  0  1]\n",
      " [ 4  3  4  0  3  7  2  0  0  0  2  6  4 10  1 14  3]\n",
      " [ 0  0 10 13  0  0  7  6  0  0  1  0  0  0  8  1 23]]\n",
      "==================================================\n",
      "Model: Support Vector Classifier\n",
      "Accuracy: 0.6386554621848739\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.65      0.59        68\n",
      "           1       0.60      0.83      0.70        72\n",
      "           2       0.55      0.70      0.62        57\n",
      "           3       0.68      0.83      0.74        58\n",
      "           4       0.57      0.12      0.20        66\n",
      "           5       0.45      0.30      0.36        76\n",
      "           6       0.72      0.96      0.82        71\n",
      "           7       0.83      0.87      0.85        61\n",
      "           8       0.59      0.79      0.68        53\n",
      "           9       0.38      0.33      0.35        61\n",
      "          10       0.83      0.83      0.83        63\n",
      "          11       0.82      0.51      0.63        53\n",
      "          12       0.61      0.54      0.57        68\n",
      "          13       0.52      0.84      0.64        55\n",
      "          14       0.85      0.93      0.89        57\n",
      "          15       0.65      0.44      0.53        63\n",
      "          16       0.71      0.51      0.59        69\n",
      "\n",
      "    accuracy                           0.64      1071\n",
      "   macro avg       0.64      0.65      0.62      1071\n",
      "weighted avg       0.64      0.64      0.62      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[44  6  0  0  0  4  0  0  3  4  7  0  0  0  0  0  0]\n",
      " [ 1 60  0  0  0  1  0  0  4  0  0  0  1  4  0  1  0]\n",
      " [ 0  1 40  2  0  0  5  2  0  0  0  0  2  0  0  4  1]\n",
      " [ 0  0  3 48  0  0  0  0  0  0  0  0  0  0  2  0  5]\n",
      " [ 6  6  8  0  8  7  5  1  2  8  0  2  6  2  1  3  1]\n",
      " [ 7  7  1  0  1 23  1  1  6 12  0  1  1 13  0  2  0]\n",
      " [ 0  0  0  0  0  0 68  0  0  1  1  0  0  0  0  0  1]\n",
      " [ 0  0  0  3  0  0  0 53  0  0  0  0  0  0  1  0  4]\n",
      " [ 2  8  0  0  0  1  0  0 42  0  0  0  0  0  0  0  0]\n",
      " [ 9  0  0  0  0  5  7  0  4 20  1  0  6  6  0  3  0]\n",
      " [ 2  3  3  0  0  0  0  0  1  1 52  0  0  1  0  0  0]\n",
      " [ 1  2  2  0  2  5  0  1  3  3  1 27  2  3  0  1  0]\n",
      " [ 3  2  3  2  2  1  7  0  3  0  1  0 37  5  1  0  1]\n",
      " [ 0  3  0  0  0  1  0  0  3  0  0  1  0 46  0  0  1]\n",
      " [ 0  0  0  0  0  0  0  3  0  0  0  0  1  0 53  0  0]\n",
      " [ 5  2  4  1  1  3  0  1  0  4  0  2  4  8  0 28  0]\n",
      " [ 0  0  9 15  0  0  2  2  0  0  0  0  1  0  4  1 35]]\n",
      "==================================================\n",
      "Model: Random Forest Classifier\n",
      "Accuracy: 0.834733893557423\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.88      0.80        68\n",
      "           1       0.82      1.00      0.90        72\n",
      "           2       0.78      0.98      0.87        57\n",
      "           3       0.82      0.97      0.89        58\n",
      "           4       0.78      0.38      0.51        66\n",
      "           5       0.58      0.38      0.46        76\n",
      "           6       0.91      1.00      0.95        71\n",
      "           7       0.96      0.90      0.93        61\n",
      "           8       0.78      1.00      0.88        53\n",
      "           9       0.70      0.69      0.69        61\n",
      "          10       0.91      0.98      0.95        63\n",
      "          11       0.95      0.77      0.85        53\n",
      "          12       0.95      0.87      0.91        68\n",
      "          13       0.78      0.98      0.87        55\n",
      "          14       0.93      0.98      0.96        57\n",
      "          15       0.90      0.73      0.81        63\n",
      "          16       0.90      0.83      0.86        69\n",
      "\n",
      "    accuracy                           0.83      1071\n",
      "   macro avg       0.84      0.84      0.83      1071\n",
      "weighted avg       0.83      0.83      0.82      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[60  4  0  0  1  1  0  0  0  0  1  0  0  1  0  0  0]\n",
      " [ 0 72  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 56  0  0  0  0  0  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  0  0 56  0  0  0  0  0  0  0  0  0  0  2  0  0]\n",
      " [ 4  3  8  1 25  9  1  0  3  3  1  0  1  1  1  2  3]\n",
      " [10  5  0  0  3 29  1  0  6 11  1  0  0  9  0  1  0]\n",
      " [ 0  0  0  0  0  0 71  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  5  0  0  0 55  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 53  0  0  0  0  0  0  0  0]\n",
      " [ 3  1  1  0  0  4  4  0  2 42  1  0  2  0  0  1  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0 62  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  1  4  0  0  3  1  0 41  0  1  0  0  1]\n",
      " [ 1  0  2  0  2  0  1  0  0  1  1  0 59  0  0  0  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 54  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0  0  0  0  0 56  0  0]\n",
      " [ 3  2  1  0  0  3  0  0  1  2  0  2  0  3  0 46  0]\n",
      " [ 0  0  4  6  0  0  0  1  0  0  1  0  0  0  0  0 57]]\n",
      "==================================================\n",
      "Model: K Nearest Neighbors\n",
      "Accuracy: 0.6834733893557423\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.66      0.60        68\n",
      "           1       0.74      0.86      0.79        72\n",
      "           2       0.59      0.91      0.72        57\n",
      "           3       0.67      0.79      0.72        58\n",
      "           4       0.33      0.14      0.19        66\n",
      "           5       0.43      0.20      0.27        76\n",
      "           6       0.77      0.89      0.82        71\n",
      "           7       0.93      0.61      0.73        61\n",
      "           8       0.71      0.87      0.78        53\n",
      "           9       0.48      0.49      0.49        61\n",
      "          10       0.82      0.94      0.87        63\n",
      "          11       0.68      0.60      0.64        53\n",
      "          12       0.77      0.79      0.78        68\n",
      "          13       0.68      0.85      0.76        55\n",
      "          14       0.88      0.91      0.90        57\n",
      "          15       0.68      0.68      0.68        63\n",
      "          16       0.69      0.58      0.63        69\n",
      "\n",
      "    accuracy                           0.68      1071\n",
      "   macro avg       0.67      0.69      0.67      1071\n",
      "weighted avg       0.67      0.68      0.66      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[45  3  0  0  0  5  2  0  1  4  6  0  0  0  0  2  0]\n",
      " [ 3 62  0  0  0  0  0  0  3  2  0  0  0  0  0  2  0]\n",
      " [ 0  0 52  0  0  0  0  0  0  0  2  0  0  0  0  1  2]\n",
      " [ 0  0  6 46  0  0  0  0  0  1  0  0  0  1  2  0  2]\n",
      " [ 6  5  8  3  9  5  6  1  3  7  1  0  3  2  3  2  2]\n",
      " [10  5  2  0  6 15  2  0  5  9  1  2  3 10  0  6  0]\n",
      " [ 0  0  1  2  0  0 63  0  0  2  0  1  1  0  0  0  1]\n",
      " [ 0  0  2  2  3  1  1 37  0  1  0  1  2  1  2  3  5]\n",
      " [ 1  6  0  0  0  0  0  0 46  0  0  0  0  0  0  0  0]\n",
      " [ 8  0  1  1  5  2  1  0  2 30  0  3  1  1  0  3  3]\n",
      " [ 2  0  0  0  0  0  0  0  0  0 59  2  0  0  0  0  0]\n",
      " [ 2  1  0  0  1  6  1  0  1  2  1 32  2  3  0  0  1]\n",
      " [ 2  1  2  1  0  1  1  0  0  2  1  2 54  0  0  0  1]\n",
      " [ 0  0  3  0  0  0  0  0  2  0  0  1  0 47  0  1  1]\n",
      " [ 0  0  1  2  0  0  2  0  0  0  0  0  0  0 52  0  0]\n",
      " [ 2  1  2  3  2  0  0  0  2  2  0  3  0  3  0 43  0]\n",
      " [ 0  0  8  9  1  0  3  2  0  0  1  0  4  1  0  0 40]]\n",
      "==================================================\n",
      "Model: Decision Tree Classifier\n",
      "Accuracy: 0.7002801120448179\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.68      0.68        68\n",
      "           1       0.80      0.90      0.85        72\n",
      "           2       0.70      0.79      0.74        57\n",
      "           3       0.78      0.90      0.83        58\n",
      "           4       0.41      0.36      0.38        66\n",
      "           5       0.39      0.29      0.33        76\n",
      "           6       0.86      0.87      0.87        71\n",
      "           7       0.90      0.74      0.81        61\n",
      "           8       0.89      0.89      0.89        53\n",
      "           9       0.47      0.43      0.45        61\n",
      "          10       0.82      0.86      0.84        63\n",
      "          11       0.59      0.74      0.66        53\n",
      "          12       0.64      0.69      0.66        68\n",
      "          13       0.68      0.76      0.72        55\n",
      "          14       0.85      0.93      0.89        57\n",
      "          15       0.64      0.57      0.61        63\n",
      "          16       0.75      0.65      0.70        69\n",
      "\n",
      "    accuracy                           0.70      1071\n",
      "   macro avg       0.70      0.71      0.70      1071\n",
      "weighted avg       0.69      0.70      0.69      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[46  3  0  0  0 10  0  0  2  2  3  0  0  2  0  0  0]\n",
      " [ 0 65  0  0  0  1  0  0  1  2  0  1  2  0  0  0  0]\n",
      " [ 0  0 45  0  2  1  2  0  0  0  0  0  2  0  0  1  4]\n",
      " [ 0  0  0 52  1  0  0  1  0  0  0  0  0  0  3  0  1]\n",
      " [ 2  4  6  1 24  5  0  0  0  6  2  4  2  1  1  5  3]\n",
      " [ 4  3  1  0  6 22  3  0  1  8  1  8  4  9  0  6  0]\n",
      " [ 0  0  3  0  3  0 62  0  0  1  1  0  0  0  0  0  1]\n",
      " [ 0  0  0  4  2  0  0 45  0  0  0  0  3  0  4  0  3]\n",
      " [ 2  1  0  0  0  0  0  0 47  1  0  2  0  0  0  0  0]\n",
      " [ 6  0  0  0  8  4  1  0  0 26  3  2  4  5  0  2  0]\n",
      " [ 2  1  0  0  1  0  0  0  0  4 54  0  1  0  0  0  0]\n",
      " [ 0  1  0  0  2  5  1  0  1  1  0 39  2  1  0  0  0]\n",
      " [ 0  0  1  1  3  3  3  0  1  1  1  2 47  0  0  3  2]\n",
      " [ 1  1  1  0  2  2  0  0  0  3  0  0  2 42  0  1  0]\n",
      " [ 0  0  1  1  0  0  0  1  0  0  0  0  0  0 53  0  1]\n",
      " [ 4  2  1  0  4  4  0  0  0  0  1  8  1  2  0 36  0]\n",
      " [ 0  0  5  8  1  0  0  3  0  0  0  0  4  0  1  2 45]]\n",
      "==================================================\n",
      "Model: Gaussian Naive Bayes\n",
      "Accuracy: 0.3081232492997199\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.21      0.30        68\n",
      "           1       0.64      0.54      0.59        72\n",
      "           2       0.15      0.05      0.08        57\n",
      "           3       0.40      0.07      0.12        58\n",
      "           4       0.56      0.08      0.13        66\n",
      "           5       0.52      0.17      0.26        76\n",
      "           6       0.31      1.00      0.47        71\n",
      "           7       0.87      0.77      0.82        61\n",
      "           8       0.71      0.19      0.30        53\n",
      "           9       0.29      0.03      0.06        61\n",
      "          10       0.71      0.35      0.47        63\n",
      "          11       0.62      0.25      0.35        53\n",
      "          12       0.47      0.10      0.17        68\n",
      "          13       0.11      0.96      0.20        55\n",
      "          14       0.00      0.00      0.00        57\n",
      "          15       0.42      0.08      0.13        63\n",
      "          16       0.44      0.32      0.37        69\n",
      "\n",
      "    accuracy                           0.31      1071\n",
      "   macro avg       0.46      0.30      0.28      1071\n",
      "weighted avg       0.46      0.31      0.29      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[14  0  0  0  0  3  4  0  1  0  3  2  0 41  0  0  0]\n",
      " [ 0 39  0  0  0  1  3  0  2  0  0  0  2 25  0  0  0]\n",
      " [ 0  0  3  0  1  0 16  0  0  0  0  0  0 31  0  3  3]\n",
      " [ 0  0  0  4  0  0 16  0  0  0  0  0  0 22  3  0 13]\n",
      " [ 3  2  1  2  5  3 12  1  0  1  0  3  3 26  0  1  3]\n",
      " [ 4  6  0  0  1 13 13  0  0  1  0  1  2 34  0  1  0]\n",
      " [ 0  0  0  0  0  0 71  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  4 47  0  0  0  0  0  3  0  0  6]\n",
      " [ 0  3  0  0  0  0  0  0 10  1  1  0  0 38  0  0  0]\n",
      " [ 2  1  1  0  1  2 16  0  0  2  4  1  1 30  0  0  0]\n",
      " [ 3  6  0  0  0  0  9  0  0  1 22  0  0 22  0  0  0]\n",
      " [ 0  0  0  0  0  0 13  0  0  0  0 13  0 25  0  2  0]\n",
      " [ 0  3  9  0  0  0 18  0  1  0  1  0  7 28  0  0  1]\n",
      " [ 0  1  0  0  0  1  0  0  0  0  0  0  0 53  0  0  0]\n",
      " [ 0  0  0  0  0  0  9  3  0  0  0  0  0 45  0  0  0]\n",
      " [ 0  0  1  0  1  2  6  0  0  1  0  1  0 44  0  5  2]\n",
      " [ 0  0  5  3  0  0 18  3  0  0  0  0  0 18  0  0 22]]\n",
      "==================================================\n",
      "Model: AdaBoost Classifier\n",
      "Accuracy: 0.22969187675070027\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        68\n",
      "           1       1.00      0.60      0.75        72\n",
      "           2       0.26      0.56      0.36        57\n",
      "           3       0.00      0.00      0.00        58\n",
      "           4       0.00      0.00      0.00        66\n",
      "           5       0.00      0.00      0.00        76\n",
      "           6       0.28      0.75      0.41        71\n",
      "           7       0.00      0.00      0.00        61\n",
      "           8       0.15      1.00      0.27        53\n",
      "           9       0.00      0.00      0.00        61\n",
      "          10       0.18      0.38      0.25        63\n",
      "          11       0.00      0.00      0.00        53\n",
      "          12       0.00      0.00      0.00        68\n",
      "          13       0.00      0.00      0.00        55\n",
      "          14       0.00      0.00      0.00        57\n",
      "          15       0.00      0.00      0.00        63\n",
      "          16       0.17      0.59      0.27        69\n",
      "\n",
      "    accuracy                           0.23      1071\n",
      "   macro avg       0.12      0.23      0.13      1071\n",
      "weighted avg       0.13      0.23      0.14      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 0  0  0  0  0  0  0  0 68  0  0  0  0  0  0  0  0]\n",
      " [ 0 43  0  0  0  0  0  0 21  0  8  0  0  0  0  0  0]\n",
      " [ 0  0 32  0  0  0 15  0  0  0  0  0  0  0  0  0 10]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 58]\n",
      " [ 0  0 14  0  0  0  9  0 27  0 11  0  0  0  0  0  5]\n",
      " [ 0  0  0  0  0  0 10  0 45  0 21  0  0  0  0  0  0]\n",
      " [ 0  0 17  0  0  0 53  0  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 61]\n",
      " [ 0  0  0  0  0  0  0  0 53  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  3  0  0  0 18  0 24  0 16  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  8  0 31  0 24  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 15  0 22  0 16  0  0  0  0  0  0]\n",
      " [ 0  0 17  0  0  0 22  0 12  0 10  0  0  0  0  0  7]\n",
      " [ 0  0  1  0  0  0 24  0 16  0 14  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 57]\n",
      " [ 0  0  9  0  0  0 15  0 28  0 11  0  0  0  0  0  0]\n",
      " [ 0  0 28  0  0  0  0  0  0  0  0  0  0  0  0  0 41]]\n",
      "==================================================\n",
      "Model: Gradient Boosting Classifier\n",
      "Accuracy: 0.7404295051353875\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.82      0.75        68\n",
      "           1       0.81      0.96      0.88        72\n",
      "           2       0.60      0.81      0.69        57\n",
      "           3       0.81      0.95      0.87        58\n",
      "           4       0.64      0.24      0.35        66\n",
      "           5       0.45      0.38      0.41        76\n",
      "           6       0.78      0.97      0.87        71\n",
      "           7       0.97      0.92      0.94        61\n",
      "           8       0.74      1.00      0.85        53\n",
      "           9       0.47      0.39      0.43        61\n",
      "          10       0.88      0.94      0.91        63\n",
      "          11       0.80      0.60      0.69        53\n",
      "          12       0.80      0.66      0.73        68\n",
      "          13       0.70      0.96      0.81        55\n",
      "          14       0.89      0.98      0.93        57\n",
      "          15       0.74      0.49      0.59        63\n",
      "          16       0.77      0.64      0.70        69\n",
      "\n",
      "    accuracy                           0.74      1071\n",
      "   macro avg       0.74      0.75      0.73      1071\n",
      "weighted avg       0.73      0.74      0.72      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[56  4  0  0  1  2  0  0  1  3  0  1  0  0  0  0  0]\n",
      " [ 0 69  0  0  0  1  0  0  2  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 46  1  0  1  4  0  0  0  0  0  1  0  0  0  4]\n",
      " [ 0  0  0 55  0  0  0  1  0  0  0  0  0  0  1  0  1]\n",
      " [ 4  2 11  0 16  9  0  0  3  7  2  0  4  3  1  2  2]\n",
      " [ 9  4  0  0  4 29  1  0  4  8  0  1  2 10  0  4  0]\n",
      " [ 0  0  0  0  0  1 69  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  4  0  0  0 56  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  0  0  0  0  0  0  0 53  0  0  0  0  0  0  0  0]\n",
      " [ 4  0  5  0  1  7  5  0  4 24  5  3  1  0  0  2  0]\n",
      " [ 3  1  0  0  0  0  0  0  0  0 59  0  0  0  0  0  0]\n",
      " [ 2  3  0  0  1  3  3  0  2  5  0 32  0  2  0  0  0]\n",
      " [ 1  0  3  0  1  3  3  0  1  1  1  0 45  3  1  3  2]\n",
      " [ 1  0  1  0  0  0  0  0  0  0  0  0  0 53  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 56  0  1]\n",
      " [ 2  2  3  0  1  8  1  0  2  2  0  3  1  5  0 31  2]\n",
      " [ 0  0  8  8  0  0  2  1  0  0  0  0  2  0  4  0 44]]\n",
      "==================================================\n",
      "Model: XGBoost Classifier\n",
      "Accuracy: 0.8132586367880486\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77        68\n",
      "           1       0.86      0.94      0.90        72\n",
      "           2       0.76      0.95      0.84        57\n",
      "           3       0.83      0.95      0.89        58\n",
      "           4       0.87      0.41      0.56        66\n",
      "           5       0.51      0.41      0.45        76\n",
      "           6       0.90      0.99      0.94        71\n",
      "           7       0.96      0.89      0.92        61\n",
      "           8       0.82      1.00      0.90        53\n",
      "           9       0.59      0.61      0.60        61\n",
      "          10       0.97      0.95      0.96        63\n",
      "          11       0.75      0.74      0.74        53\n",
      "          12       0.82      0.87      0.84        68\n",
      "          13       0.80      0.95      0.87        55\n",
      "          14       0.92      0.98      0.95        57\n",
      "          15       0.80      0.71      0.76        63\n",
      "          16       0.93      0.83      0.88        69\n",
      "\n",
      "    accuracy                           0.81      1071\n",
      "   macro avg       0.81      0.82      0.81      1071\n",
      "weighted avg       0.81      0.81      0.80      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[54  3  0  0  1  3  0  0  0  4  0  1  0  1  0  1  0]\n",
      " [ 1 68  0  0  0  1  0  0  1  1  0  0  0  0  0  0  0]\n",
      " [ 0  0 54  0  0  1  1  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0 55  0  0  0  0  0  0  0  0  0  0  2  0  1]\n",
      " [ 3  3  7  0 27  8  2  0  2  5  2  0  4  0  1  1  1]\n",
      " [ 8  2  0  0  1 31  1  0  2  9  0  5  2 10  0  5  0]\n",
      " [ 0  0  0  0  0  0 70  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  5  0  0  0 54  0  0  0  0  0  0  1  0  1]\n",
      " [ 0  0  0  0  0  0  0  0 53  0  0  0  0  0  0  0  0]\n",
      " [ 2  0  5  0  0  5  2  0  2 37  0  3  4  0  0  1  0]\n",
      " [ 2  0  0  0  0  0  0  0  1  0 60  0  0  0  0  0  0]\n",
      " [ 0  2  0  0  0  4  2  0  2  3  0 39  1  0  0  0  0]\n",
      " [ 0  0  1  0  1  3  0  0  1  1  0  0 59  0  1  0  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0 52  0  2  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0  0  0  0  0 56  0  0]\n",
      " [ 2  1  1  0  0  5  0  0  1  2  0  3  1  2  0 45  0]\n",
      " [ 0  0  3  6  1  0  0  1  0  0  0  0  0  0  0  1 57]]\n"
     ]
    }
   ],
   "source": [
    "# Define classifiers\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Support Vector Classifier\": SVC(),\n",
    "    \"Random Forest Classifier\": RandomForestClassifier(),\n",
    "    \"K Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Decision Tree Classifier\": DecisionTreeClassifier(),\n",
    "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "    \"AdaBoost Classifier\": AdaBoostClassifier(),\n",
    "    \"Gradient Boosting Classifier\": GradientBoostingClassifier(),\n",
    "    \"XGBoost Classifier\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "for name, model in models.items():\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Model:\", name)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Random Forest Classifier Evaluation ===\n",
      "Accuracy: 0.8338001867413632\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.85      0.79        68\n",
      "           1       0.77      1.00      0.87        72\n",
      "           2       0.80      0.96      0.87        57\n",
      "           3       0.85      0.97      0.90        58\n",
      "           4       0.85      0.44      0.58        66\n",
      "           5       0.62      0.43      0.51        76\n",
      "           6       0.92      1.00      0.96        71\n",
      "           7       0.96      0.89      0.92        61\n",
      "           8       0.83      0.98      0.90        53\n",
      "           9       0.72      0.69      0.71        61\n",
      "          10       0.91      0.97      0.94        63\n",
      "          11       0.87      0.75      0.81        53\n",
      "          12       0.91      0.87      0.89        68\n",
      "          13       0.77      0.96      0.85        55\n",
      "          14       0.93      0.98      0.96        57\n",
      "          15       0.90      0.70      0.79        63\n",
      "          16       0.88      0.84      0.86        69\n",
      "\n",
      "    accuracy                           0.83      1071\n",
      "   macro avg       0.84      0.84      0.83      1071\n",
      "weighted avg       0.83      0.83      0.82      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[58  5  0  0  1  2  0  0  0  1  0  0  0  1  0  0  0]\n",
      " [ 0 72  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 55  0  0  0  0  0  0  0  0  0  0  0  0  0  2]\n",
      " [ 0  0  0 56  0  0  0  0  0  0  0  0  0  0  2  0  0]\n",
      " [ 5  3  6  0 29  6  0  0  3  5  2  0  1  0  1  1  4]\n",
      " [ 9  6  0  0  0 33  2  0  4  7  0  3  1  9  0  2  0]\n",
      " [ 0  0  0  0  0  0 71  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  5  0  0  0 54  0  0  0  0  0  0  1  0  1]\n",
      " [ 0  1  0  0  0  0  0  0 52  0  0  0  0  0  0  0  0]\n",
      " [ 3  2  1  0  0  4  4  0  1 42  2  0  1  1  0  0  0]\n",
      " [ 2  0  0  0  0  0  0  0  0  0 61  0  0  0  0  0  0]\n",
      " [ 0  2  0  0  2  4  0  0  1  1  0 40  2  1  0  0  0]\n",
      " [ 0  1  2  0  1  1  0  0  1  1  1  0 59  0  0  0  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 53  0  2  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0  0  0  0  0 56  0  0]\n",
      " [ 2  2  2  0  1  3  0  0  1  1  0  3  0  4  0 44  0]\n",
      " [ 0  0  3  5  0  0  0  1  0  0  1  0  1  0  0  0 58]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Model - detailed evaluation\n",
    "print(\"\\n=== Random Forest Classifier Evaluation ===\")\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and scaler\n",
    "pickle.dump(scaler, open(\"scaler.pkl\", 'wb'))\n",
    "pickle.dump(rf_model, open(\"model.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommendation system\n",
    "class_names = [\n",
    "    'Lawyer', 'Doctor', 'Government Officer', 'Artist', 'Unknown', 'Software Engineer',\n",
    "    'Teacher', 'Business Owner', 'Scientist', 'Banker', 'Writer', 'Accountant', 'Designer',\n",
    "    'Construction Engineer', 'Game Developer', 'Stock Investor', 'Real Estate Developer'\n",
    "]\n",
    "\n",
    "def Recommendations(gender, part_time_job, absence_days, extracurricular_activities,\n",
    "                    weekly_self_study_hours, math_score, history_score, physics_score,\n",
    "                    chemistry_score, biology_score, english_score, geography_score,\n",
    "                    total_score, average_score):\n",
    "    # Encode input\n",
    "    gender_encoded = 1 if gender.lower() == 'female' else 0\n",
    "    part_time_job_encoded = 1 if part_time_job else 0\n",
    "    extracurricular_activities_encoded = 1 if extracurricular_activities else 0\n",
    "\n",
    "    # Feature array\n",
    "    feature_array = np.array([[gender_encoded, part_time_job_encoded, absence_days,\n",
    "                               extracurricular_activities_encoded, weekly_self_study_hours,\n",
    "                               math_score, history_score, physics_score, chemistry_score,\n",
    "                               biology_score, english_score, geography_score, total_score, average_score]])\n",
    "\n",
    "    # Scale and predict\n",
    "    scaled_features = scaler.transform(feature_array)\n",
    "    probabilities = rf_model.predict_proba(scaled_features)\n",
    "\n",
    "    # Get top predictions\n",
    "    top_classes_idx = np.argsort(-probabilities[0])[:5]\n",
    "    return [(class_names[idx], probabilities[0][idx]) for idx in top_classes_idx]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
